#!/usr/bin/perl
use strict;
use warnings;
use Cwd qw(abs_path);
use Data::UUID;
use File::Basename qw(basename);
use JSON qw(from_json);
use Time::HiRes qw(time);

use utf8;
use open qw(:std :encoding(UTF-8));

my $CACHE_BASE_DIR = "$ENV{HOME}/.cache/ebook-audiobook-wordtiming";
my $CACHE_DIR_AUDIOBOOK_VOSK_WORDS_JSON = "$CACHE_BASE_DIR/audiobook-vosk-words-json";
my $CACHE_DIR_EBOOK_COOLREADER_SENTENCEINFO = "$CACHE_BASE_DIR/ebook-coolreader-sentenceinfo";
my $CACHE_DIR_EBOOK_PANDOC_PLAINTEXT = "$CACHE_BASE_DIR/ebook-pandoc-plaintext";

my $FILE_INFO_CACHE = "$CACHE_BASE_DIR/file-info";

my $MODE_WORDTIMING = "word-timing";
my $MODE_CACHE_EBOOK = "cache-ebook";
my $MODE_CACHE_AUDIOBOOK = "cache-audiobook";

my $PYTHON_VOSK_VENV = "/opt/python-vosk";

my $EXEC = basename $0;

my $USAGE = "Usage:
  $EXEC -h | --help
    show this message

  $EXEC [OPTS] EBOOK_FILE AUDIOBOOK_FILE [AUDIOBOOK_FILE AUDIOBOOK_FILE]
    Compare EBOOK_FILE and AUDIOBOOK_FILE(s), and generate an OUTPUT_WORDTIMING_FILE,
      containing each word in the *EBOOK*,
      with the best-guess start-time and filename from the *AUDIOBOOK*.
    Also generate OUTPUT_SENTENCEINFO_FILE if coolreader is used,
      containing one line per sentence (selectable segment) in the ebook,
      with the coolreader DOM position of that sentence in the ebook.

    (1) AUDIOBOOK_FILE_VOSK_DATA - raw JSON from python-vosk
        -for each AUDIOBOOK_FILE:
          -ensure AUDIOBOOK_FILE_VOSK_DATA cache exists as in:
            $EXEC --cache-audiobook AUDIOBOOK_FILE_VOSK_DATA
            (runs external tool vosk-words-json, which performs speech-to-text)
          -read AUDIOBOOK_FILE_VOSK_DATA from cache
    (2) AUDIOBOOK_WORDTIMING - spoken word timings for each word in audiobook
        -for each AUDIOBOOK_FILE
          -parse AUDIOBOOK_FILE_VOSK_DATA into AUDIOBOOK_WORDTIMING
          -for each parsed word in AUDIOBOOK_FILE, fetch:
            -AUDIOBOOK_WORD
            -AUDIOBOOK_FILE
            -AUDIOBOOK_START_POS
    (3) AUDIOBOOK_WORDS_FILE - file containing just the words in audiobook
        -create AUDIOBOOK_WORDS_FILE from AUDIOBOOK_WORDTIMING
          -write just AUDIOBOOK_WORD, one word per line
    (4) EBOOK_PARSED_CONTENT - structured data containing plaintext ebook text
        -ensure EBOOK_PARSED_CONTENT cache exists as in:
          $EXEC --cache-ebook EBOOK_FILE
          (runs one or more external EBOOK_PARSER commands)
        -select exactly one EBOOK_PARSER (see --ebook-parser):
          cr3:    EBOOK_PARSED_CONTENT=COOLREADER_SENTENCE_INFO
          pandoc: EBOOK_PARSED_CONTENT=PANDOC_PLAINTEXT
        -extract EBOOK_TEXT_SENTENCES from EBOOK_PARSED_CONTENT
          -remove any metadata/non-text/positioning info
            -for COOLREADER_SENTENCE_INFO: remove sentence positioning info
            -for PANDOC_PLAINTEXT: nothing to remove
          -separate into sentences
            -for COOLREADER_SENTENCE_INFO: treat each line is a parsed sentence
            -for PANDOC_PLAINTEXT: separate at periods, semi-colons, and multiple newlines
        -if COOLREADER_SENTENCE_INFO is available:
          -write COOLREADER_SENTENCE_INFO to OUTPUT_SENTENCEINFO_FILE
    (5) EBOOK_WORDS_FILE - file containing just the words in ebook
        -replace some unicode quote characters in EBOOK_TEXT_SENTENCES
        -write one word per line to EBOOK_WORDS_FILE
          -for each sentence inf EBOOK_TEXT_SENTENCES:
            -parse all substrings of letters/numbers/single-quotes as 'words'
            -convert words to lowercase and write to EBOOK_WORDS_FILE
    (6) EBOOK_AUDIOBOOK_WORDS_DIFF - annotated diff of EBOOK_WORDS_FILE and AUDIOBOOK_WORDS_FILE
        -find the longest common subsequence of EBOOK_WORDS_FILE and AUDIOBOOK_WORDS_FILE
          -use: `diff -y EBOOK_WORDS_FILE AUDIOBOOK_WORDS_FILE`
        -each line is one word, with a status:
          ebook-only, audiobook-only, similar, identical
    (7) OUTPUT_WORDTIMING_FILE - each word from ebook with start time+file from audiobook
        -for each EBOOK_WORD, get the closest audiobook word using EBOOK_AUDIOBOOK_WORDS_DIFF:
          -for all lines with status 'identical', match the ebook word to that audiobook word
          -for all lines with status 'similar', match the ebook word to that audiobook word
          -for all ebook-only lines, match that ebook word with the previously matched audiobook word
            (or the first audiobook word if none are matched)
          -discard all audiobook-only lines
        -for each EBOOK_WORD, get timing and format word:
          -extract AUDIOBOOK_FILE and AUDIOBOOK_START_POS from AUDIOBOOK_WORDTIMING
          -format line as AUDIOBOOK_START_POS,EBOOK_WORD,AUDIOBOOK_FILE
          -write line to OUTPUT_WORDTIMING_FILE

  $EXEC [OPTS] --cache-ebook EBOOK_FILE [EBOOK_FILE EBOOK_FILE]
    -select EBOOK_PARSER(s) to generate EBOOK_PARSED_CONTENT, using the command PATH and OPTS
        cr3:    EBOOK_PARSED_CONTENT=COOLREADER_SENTENCE_INFO
        pandoc: EBOOK_PARSED_CONTENT=PANDOC_PLAINTEXT
    -for each EBOOK_FILE:
      -if EBOOK_PARSER cr3 enabled:
        -check for cached COOLREADER_SENTENCE_INFO
          -if not cached:
            -parse EBOOK_FILE into sentences with `cr3 --get-sentence-info EBOOK_FILE CACHE_FILE`
            -compress CACHE_FILE and store result in cache dir:
             $CACHE_DIR_EBOOK_COOLREADER_SENTENCEINFO
      -if EBOOK_PARSER pandoc enabled:
        -check for cached PANDOC_PLAINTEXT
          -if not cached:
            -parse EBOOK_FILE into plaintext with `pandoc -t plain EBOOK_FILE -o CACHE_FILE`
            -compress CACHE_FILE and store result in:
             $CACHE_DIR_EBOOK_PANDOC_PLAINTEXT
      -if no EBOOK_PARSER is available:
        -fail with an error message

  $EXEC [OPTS] --cache-audiobook AUDIOBOOK_FILE [AUDIOBOOK_FILE AUDIOBOOK_FILE]
    -for each AUDIOBOOK_FILE:
      -check for cached Vosk data
        -if not cached:
          -convert AUDIOBOOK_FILE to mono WAVE (if it is not already)
          -generate Vosk result data, with timing for each word, with `vosk-words-json`
          -compress and store resut in cache dir:
           $CACHE_DIR_AUDIOBOOK_VOSK_WORDS_JSON
           (about 100KiB, compressed, per hour of audiobook)

  OPTS
    -o OUTPUT_WORDTIMING_FILE | --output-wordtiming=OUTPUT_FILE
      write the final wordtiming (ebook words + audiobook start times) to OUTPUT_FILE
      default is EBOOK_FILE, with any file extension removed, and .wordtiming appended
        e.g. path/to/books/tale_of_two_cities.epub => path/to/books/tale_of_two_cities.wordtiming

    -s OUTPUT_SENTENCEINFO_FILE | --output-sentenceinfo OUTPUT_SENTENCEINFO_FILE
      copy the cached sentenceinfo, uncompressed, to OUTPUT_SENTENCEINFO_FILE
      default is EBOOK_FILE, with any file extension removed, and .sentenceinfo appended
        e.g. path/to/books/tale_of_two_cities.epub => path/to/books/tale_of_two_cities.wordtiming
      NOTE: this has no effect unless EBOOK_PARSER 'cr3' is used

    --vosk-model-path=MODEL_PATH
      pass --model-path=MODEL_PATH to vosk-words-json
    --vosk-model-name=MODEL_NAME
      pass --model-name=MODEL_NAME to vosk-words-json
    --vosk-model-lang=MODEL_LANG
      pass --model-lang=MODEL_LANG to vosk-words-json

    --meld
      before outputting word timings, open meld to view diff of ebook+audiobooks words
        run: `meld EBOOK_WORDS_FILE AUDIOBOOK_WORD_FILE`

    --ebook-parser-first
      check command PATH for each EBOOK_PARSER, and use only the first available
      EBOOK_PARSER=cr3
        check `cr3` on command PATH
      EBOOK_PARSER=pandoc
        check `pandoc` on command PATH

    --cr3
      same as: --ebook-parser=cr3
      (this is the default)
    --pandoc
      same as: --ebook-parser=pandoc

    --ebook-parser=EBOOK_PARSER
      force use of specific EBOOK_PARSER, without checking PATH

      NOTE: If multiple parsers are enabled with --ebook-parser=*,
              they are all are generated+cached,
              but only the highest-listed below is used to generate EBOOK_WORDS_FILE.

    EBOOK_PARSER is one of:
      cr3
        get EBOOK_PARSED_CONTENT=COOLREADER_SENTENCE_INFO
        using: `cr3 --get-sentence-info ...`
      pandoc
        get EBOOK_PARSED_CONTENT=PANDOC_PLAINTEXT
        using: `pandoc -t plain ...`
";

sub getEbookWordFile($);
sub getAudiobookWordFile(@);
sub ensureCacheFileEbookCoolreaderSentenceInfo($$);
sub runCoolreaderSentenceInfo($$);
sub ensureCacheFileEbookPandocPlaintext($$);
sub runPandocPlaintext($$);
sub ensureCacheFileAudiobookVoskWordsJson($$);
sub runVoskWordsJson($$@);
sub ensureCacheFile($$$$$);
sub getEbookWordFileTimestamps($$@);
sub getCleanFileName($);
sub globFirst($);
sub ensureFileInfoCache($$);
sub readFileInfoCache();
sub appendFileInfoCache($$);
sub getRelFile($);
sub getMountpointOfFile($);
sub md5sum($);
sub readFile($);
sub readFileXZ($);
sub isExecAvailable($);
sub writeFile($$);
sub nowMillis();
sub run(@);

sub main(@){
  my @files;
  my $outputWordtimingFile;
  my $outputSentenceInfoFile;
  my @voskArgs;
  my $meld = 0;
  my $mode = $MODE_WORDTIMING;
  my $checkParserPaths = 0;
  my @ebookParsers = qw(cr3);
  while(@_ > 0){
    my $arg = shift;
    if($arg =~ /^(-h|--help)$/){
      print $USAGE;
      exit 0;
    }elsif($arg =~ /^(-o|--output-wordtiming)$/ and @_ > 0){
      $outputWordtimingFile = shift @_;
    }elsif($arg =~ /^--output-wordtiming=(.+)$/){
      $outputWordtimingFile = $1;
    }elsif($arg =~ /^(-s|--output-sentenceinfo)$/ and @_ > 0){
      $outputSentenceInfoFile = shift @_;
    }elsif($arg =~ /^--output-sentenceinfo=(.+)$/){
      $outputSentenceInfoFile = $1;
    }elsif($arg =~ /^(--cache-ebook)$/){
      $mode = $MODE_CACHE_EBOOK;
    }elsif($arg =~ /^(--cache-audiobook)$/){
      $mode = $MODE_CACHE_AUDIOBOOK;
    }elsif($arg =~ /^--vosk-model-path=(.+)$/){
      push @voskArgs, "--model-path=$1";
    }elsif($arg =~ /^--vosk-model-name=(.+)$/){
      push @voskArgs, "--model-name=$1";
    }elsif($arg =~ /^--vosk-model-lang=(.+)$/){
      push @voskArgs, "--model-lang=$1";
    }elsif($arg =~ /^(--meld)$/){
      $meld = 1;
    }elsif($arg =~ /^(--ebook-parser-first)$/){
      $checkParserPaths = 1;
      @ebookParsers = ();
    }elsif($arg =~ /^--ebook-parser=(.+)$/){
      push @ebookParsers, $1;
      $checkParserPaths = 0;
    }elsif($arg =~ /^(--cr3)$/){
      push @ebookParsers, "cr3";
      $checkParserPaths = 0;
    }elsif($arg =~ /^(--pandoc)$/){
      push @ebookParsers, "pandoc";
      $checkParserPaths = 0;
    }elsif(-f $arg){
      push @files, $arg;
    }else{
      die "$USAGE\nERROR: unknown arg $arg\n";
    }
  }

  if($checkParserPaths and isExecAvailable("cr3")){
    @ebookParsers = ("cr3");
    $checkParserPaths = 0;
  }
  if($checkParserPaths and isExecAvailable("pandoc")){
    @ebookParsers = ("pandoc");
    $checkParserPaths = 0;
  }

  if($mode eq $MODE_WORDTIMING){
    my ($ebookFile, @audiobookFiles) = @files;
    if(not defined $ebookFile){
      die "ERROR: missing EBOOK_FILE(s)\n";
    }
    if(@audiobookFiles == 0){
      die "ERROR: missing AUDIOBOOK_FILE(s)\n";
    }
    my $fileInfoCache = readFileInfoCache();

    my @audiobookWordInfo;

    for my $audioFile(@audiobookFiles){
      my $cacheFile = ensureCacheFileAudiobookVoskWordsJson($audioFile, $fileInfoCache);
      my $json = readFileXZ($cacheFile);
      my $fileName = basename $audioFile;

      my $sentences = from_json $json;
      my @words;
      for my $s(@$sentences){
        @words = (@words, @{$$s{result}});
      }

      for my $word(@words){
        push @audiobookWordInfo, {
          word  => $$word{word},
          start => $$word{start},
          file  => $fileName,
        };
      }
    }
    my $audiobookWordFile = getAudiobookWordFile(@audiobookWordInfo);

    my $ebookParsedContentCacheFiles = {};
    for my $ebookParser(@ebookParsers){
      if($ebookParser eq "cr3"){
        $$ebookParsedContentCacheFiles{cr3} =
          ensureCacheFileEbookCoolreaderSentenceInfo($ebookFile, $fileInfoCache);
      }
      if($ebookParser eq "pandoc"){
        $$ebookParsedContentCacheFiles{pandoc} =
          ensureCacheFileEbookPandocPlaintext($ebookFile, $fileInfoCache);
      }
    }
    my $ebookWordFile = getEbookWordFile($ebookParsedContentCacheFiles);

    if($meld){
      system "meld", $ebookWordFile, $audiobookWordFile;
    }

    if(not defined $outputWordtimingFile){
      $outputWordtimingFile = $ebookFile;
      $outputWordtimingFile =~ s/\.\w+$//;
      $outputWordtimingFile .= ".wordtiming";
      if(-e $outputWordtimingFile){
        die "ERROR: $outputWordtimingFile already exists\n";
      }
    }
    my $fmt = getEbookWordFileTimestamps($ebookWordFile, $audiobookWordFile, @audiobookWordInfo);
    writeFile $outputWordtimingFile, $fmt;

    if(defined $$ebookParsedContentCacheFiles{cr3}){
      my $sentenceInfoCacheFile = $$ebookParsedContentCacheFiles{cr3};

      if(not defined $outputSentenceInfoFile){
        $outputSentenceInfoFile = $ebookFile;
        $outputSentenceInfoFile =~ s/\.\w+$//;
        $outputSentenceInfoFile .= ".sentenceinfo";
      }

      my $sentenceInfo = readFileXZ $sentenceInfoCacheFile;

      if(-e $outputSentenceInfoFile){
        my $oldSentenceInfo = readFile $outputSentenceInfoFile;
        if($sentenceInfo ne $oldSentenceInfo){
          die "ERROR: $outputSentenceInfoFile already exists and differs from new sentenceinfo\n";
        }
      }else{
        writeFile $outputSentenceInfoFile, $sentenceInfo;
      }
    }
  }elsif($mode eq $MODE_CACHE_EBOOK){
    my @ebookFiles = @files;
    my $fileInfoCache = readFileInfoCache();
    for my $ebookFile(@ebookFiles){
      my $ebookParsedContentCacheFiles = {};
      for my $ebookParser(@ebookParsers){
        if($ebookParser eq "cr3"){
          $$ebookParsedContentCacheFiles{cr3} =
            ensureCacheFileEbookCoolreaderSentenceInfo($ebookFile, $fileInfoCache);
        }
        if($ebookParser eq "pandoc"){
          $$ebookParsedContentCacheFiles{pandoc} =
            ensureCacheFileEbookPandocPlaintext($ebookFile, $fileInfoCache);
        }
      }

      my @cachedParsers = sort keys %$ebookParsedContentCacheFiles;
      if(@cachedParsers == 0){
        die "ERROR: did not cache any EBOOK_PARSED_CONTENT for $ebookFile\n";
      }
      for my $parser(@cachedParsers){
        my $cacheFile = $$ebookParsedContentCacheFiles{$parser};
        if(defined $cacheFile){
          print "cached $parser EBOOK_PARSED_CONTENT for $ebookFile\n";
        }else{
          die "ERROR: did not cache $parser EBOOK_PARSED_CONTENT for $ebookFile\n";
        }
      }
    }
  }elsif($mode eq $MODE_CACHE_AUDIOBOOK){
    my @audiobookFiles = @files;
    if(@audiobookFiles == 0){
      die "ERROR: missing AUDIOBOOK_FILE(s)\n";
    }
    my $fileInfoCache = readFileInfoCache();
    for my $audioFile(@audiobookFiles){
      my $cacheFile = ensureCacheFileAudiobookVoskWordsJson($audioFile, $fileInfoCache);
      print "cached $audioFile => $cacheFile\n";
    }
  }else{
    die "ERROR: unknown mode $mode\n";
  }
}


sub getEbookWordFile($){
  my ($ebookParsedContentCacheFiles) = @_;

  my $nowMillis = nowMillis();
  my $uuid = getUUID();
  my $tmpEbookWordsFile = "/tmp/ebook-words-$nowMillis-$uuid.txt";

  my @sentences;
  if(@sentences == 0 and defined $$ebookParsedContentCacheFiles{cr3}){
    my $content = readFileXZ $$ebookParsedContentCacheFiles{cr3};
    $content =~ s/’/'/g;
    $content =~ s/^[^,]*,//gm; #remove sentence start position info

    @sentences = split /[\r\n]+/, $content;
  }
  if(@sentences == 0 and defined $$ebookParsedContentCacheFiles{pandoc}){
    my $content = readFileXZ $$ebookParsedContentCacheFiles{pandoc};
    $content =~ s/’/'/g;

    @sentences = split /(\.|\n\n+|;)/, $content;
  }

  if(@sentences == 0){
    die "ERROR: no EBOOK_PARSED_CONTENT found\n";
  }

  my $wordContent = "";
  for my $sentence(@sentences){
    #split sentence into words:
    #  -split at any amount of characters that are NOT:
    #      letters or marks or numbers or apostrophes
    #  -remove any 'words' that have no letters
    my @words = split /(?[! (\p{L} + \p{M} + \p{N} + [']) ])+/, lc $sentence;
    @words = grep {/(?[\p{L} + \p{M} + \p{N}])/} @words;
    for my $word(@words){
      $wordContent .= "$word\n";
    }
  }
  writeFile $tmpEbookWordsFile, $wordContent;
  return $tmpEbookWordsFile;
}

sub getAudiobookWordFile(@){
  my @wordInfo = @_;
  my $nowMillis = nowMillis();
  my $uuid = getUUID();
  my $tmpAudiobookWordsFile = "/tmp/audiobook-words-$nowMillis-$uuid.txt";

  my $wordContent = "";
  for my $w(@wordInfo){
    $wordContent .= "$$w{word}\n";
  }
  writeFile $tmpAudiobookWordsFile, $wordContent;
  return $tmpAudiobookWordsFile;
}

sub ensureCacheFileEbookCoolreaderSentenceInfo($$){
  my ($ebookFile, $fileInfoCache) = @_;
  return ensureCacheFile($ebookFile, $fileInfoCache,
    "sentenceinfo", $CACHE_DIR_EBOOK_COOLREADER_SENTENCEINFO, \&runCoolreaderSentenceInfo);
}
sub runCoolreaderSentenceInfo($$){
  my ($srcEbookFile, $destSentenceInfoFile) = @_;
  run "cr3", "--loglevel=INFO", "--get-sentence-info", $srcEbookFile, $destSentenceInfoFile;
}

sub ensureCacheFileEbookPandocPlaintext($$){
  my ($ebookFile, $fileInfoCache) = @_;
  return ensureCacheFile($ebookFile, $fileInfoCache,
   "txt", $CACHE_DIR_EBOOK_PANDOC_PLAINTEXT, \&runPandocPlaintext);
}
sub runPandocPlaintext($$){
  my ($srcEbookFile, $destPlaintextFile) = @_;
  run "pandoc", "-t", "plain", $srcEbookFile, "-o", $destPlaintextFile;
}

sub ensureCacheFileAudiobookVoskWordsJson($$){
  my ($audioFile, $fileInfoCache) = @_;
  return ensureCacheFile($audioFile, $fileInfoCache,
    "json", $CACHE_DIR_AUDIOBOOK_VOSK_WORDS_JSON, \&runVoskWordsJson);
}
sub runVoskWordsJson($$@){
  my ($srcAudioFile, $destJSONFile, @voskArgs) = @_;

  my $inputWaveFile = undef;
  my $deleteWaveFile = 0;

  my $origFileType = `file "$srcAudioFile"`;
  if($origFileType =~ /WAVE.*\bmono\b/){
    $inputWaveFile = $srcAudioFile;
    $deleteWaveFile = 0;
  }else{
    my $nowMillis = nowMillis();
    my $uuid = getUUID();
    my $tmpWaveFile = "/tmp/vosk-wav-file-$nowMillis-$uuid.wav";
    system "ffmpeg", "-i", $srcAudioFile, "-ac", "1", $tmpWaveFile;
    if(not -f $tmpWaveFile){
      die "ERROR: failed to create mono WAVE for $srcAudioFile\n";
    }

    $inputWaveFile = $tmpWaveFile;
    $deleteWaveFile = 1;
  }

  my $wavFileType = `file "$inputWaveFile"`;
  if($wavFileType !~ /WAVE.*\bmono\b/){
    die "ERROR: $inputWaveFile is not a mono WAVE\n";
  }

  my $voskExec = "vosk-words-json";
  $voskExec = `command -v '$voskExec'`;
  chomp $voskExec;
  if($voskExec !~ /vosk-words-json/){
    die "ERROR: could not find vosk-words-json on PATH\n";
  }

  my @voskCmd = ($voskExec, $inputWaveFile, "--output=$destJSONFile", @voskArgs);

  if(-x "$PYTHON_VOSK_VENV/bin/python3"){
    @voskCmd = ("$PYTHON_VOSK_VENV/bin/python3", @voskCmd);
  }

  run @voskCmd;

  if($deleteWaveFile){
    run "rm", $inputWaveFile;
  }
}

sub ensureCacheFile($$$$$){
  my ($file, $fileInfoCache, $fileExt, $cacheDir, $processFileSub) = @_;
  die "ERROR: $file not found\n" if not -f $file;
  my $fileInfo = ensureFileInfoCache($file, $fileInfoCache);
  my $md5 = $$fileInfo{md5};
  my $cacheFile = globFirst "$cacheDir/*-$md5.$fileExt.xz";
  if(defined $cacheFile){
    return $cacheFile;
  }

  if(not -d $cacheDir){
    run "mkdir", "-p", $cacheDir;
  }
  if(not -d $cacheDir){
    die "ERROR: $cacheDir does not exist\n";
  }
  my $cleanFileName = getCleanFileName($file);
  if($cleanFileName eq ""){
    $cleanFileName = "_";
  }
  $cacheFile = "$cacheDir/$cleanFileName-$md5.$fileExt";

  if(-e $cacheFile){
    die "ERROR: $cacheFile already exists, possible race condition\n";
  }

  &$processFileSub($file, $cacheFile);

  if(not -f $cacheFile){
    die "ERROR: $cacheFile does not exist after processing\n";
  }

  run "xz", $cacheFile;
  my $cacheFileXZ = "$cacheFile.xz";

  if(not -f $cacheFileXZ){
    die "ERROR: $cacheFileXZ does not exist, compression failed\n";
  }
  if(-e $cacheFile){
    die "ERROR: $cacheFile exists after compression\n";
  }

  return $cacheFileXZ;
}

sub getEbookWordFileTimestamps($$@){
  my ($ebookWordFile, $audiobookWordFile, @wordInfo) = @_;

  my $fmt = "";
  my @diffLines = `diff -y $ebookWordFile $audiobookWordFile`;
  my $audiobookWordIndex=0;
  for my $diffLine(@diffLines){
    $audiobookWordIndex = $#wordInfo if $audiobookWordIndex > $#wordInfo;
    my $wordInfo = $wordInfo[$audiobookWordIndex];
    my $start = $$wordInfo{start};
    my $file = $$wordInfo{file};
    if($diffLine =~ /^(\S+)\s+(\1)$/){
      #exact match
      $fmt .= "$start,$1,$file\n";
      $audiobookWordIndex++;
    }elsif($diffLine =~ /^(\S+)\s+\|\s+(\S+)$/){
      #fuzzy match
      $fmt .= "$start,$1,$file\n";
      $audiobookWordIndex++;
    }elsif($diffLine =~ /^(\S+)\s+<$/){
      #word in ebook not in audiobook
      $fmt .= "$start,$1,$file\n";
    }elsif($diffLine =~ /^\s+>\s+(\S+)$/){
      #word in audiobook not in ebook
      $audiobookWordIndex++;
    }else{
      die "ERROR: could not parse diff line:\n$diffLine";
    }
  }

  return $fmt;
}

sub getCleanFileName($){
  my ($file) = @_;
  my $cleanFileName = lc basename $file;
  $cleanFileName =~ s/\.\w+$//;
  $cleanFileName =~ s/\W+/_/g;
  $cleanFileName =~ s/__+/_/g;
  $cleanFileName =~ s/^_+//g;
  $cleanFileName =~ s/_+$//g;
  return $cleanFileName;
}

sub globFirst($){
  my ($ptrn) = @_;
  my @files = glob $ptrn;
  @files = grep {-e $_} @files;
  if(@files > 0){
    return $files[0];
  }else{
    return undef;
  }
}

sub ensureFileInfoCache($$){
  my ($file, $fileInfoCache) = @_;
  my $absFile = abs_path $file;
  my $relFile = getRelFile($absFile);

  my @stat = stat $absFile;
  my $size = $stat[7];
  my $mtime = $stat[9];

  if(defined $$fileInfoCache{$relFile}){
    my $fileInfo = $$fileInfoCache{$relFile};
    my $oldSize = $$fileInfo{size};
    my $oldMtime = $$fileInfo{mtime};
    if($mtime == $oldMtime and $size == $oldSize){
      return $fileInfo;
    }
  }

  my $md5 = md5sum $absFile;

  my $fileInfo = {
    size => $size,
    mtime => $mtime,
    md5 => $md5,
  };
  $$fileInfoCache{$relFile} = $fileInfo;

  appendFileInfoCache $relFile, $fileInfo;

  return $fileInfo;
}

sub readFileInfoCache(){
  my $fileInfoCache = {};
  if(not -f $FILE_INFO_CACHE){
    return $fileInfoCache;
  }

  my @lines = readFile $FILE_INFO_CACHE;
  for my $line(@lines){
    next if $line =~ /^\s*$/;
    if($line =~ /^(\d+),(\d+),([0-9a-f]{32}),(.+)$/){
      my ($size, $mtime, $md5, $relFile) = ($1, $2, $3, $4);
      $$fileInfoCache{$relFile} = {
        size => $size,
        mtime => $mtime,
        md5 => $md5,
      };
    }else{
      die "ERROR: malformed line in $FILE_INFO_CACHE\n$line";
    }
  }

  return $fileInfoCache;
}
sub appendFileInfoCache($$){
  my ($relFile, $fileInfo) = @_;
  my $line = "$$fileInfo{size},$$fileInfo{mtime},$$fileInfo{md5},$relFile\n";
  if(not -d $CACHE_BASE_DIR){
    run "mkdir", "-p", $CACHE_BASE_DIR;
  }
  open FH, ">> $FILE_INFO_CACHE" or die "ERROR: could not append $FILE_INFO_CACHE\n$!\n";
  print  FH $line;
  close FH;
}

sub getRelFile($){
  my ($absFile) = @_;
  my $relFile = $absFile;
  my $mountpoint = getMountpointOfFile($absFile);
  $relFile =~ s/^$mountpoint\///;
  return $relFile;
}

sub getMountpointOfFile($){
  my ($file) = @_;
  my $mountpoint = `stat -c %m \"$file\"`;
  chomp $mountpoint;
  if($mountpoint !~ /^\//){
    die "ERROR: invalid mountpoint \"$mountpoint\" for file \"$file\"\n";
  }
  return $mountpoint;
}

sub md5sum($){
  open CMD, "-|", "md5sum", $_[0];
  my $md5sum = <CMD>;
  close CMD;
  chomp $md5sum;
  if($md5sum =~ /^([0-9a-f]{32})(\s.*|$)$/){
    return $1;
  }else{
    return undef;
  }
}

sub readFile($){
  my ($file) = @_;
  open FH, "< $file" or die "ERROR: could not read $file\n$!\n";
  my @lines = <FH>;
  close FH;
  if(wantarray){
    return @lines;
  }else{
    return join '', @lines;
  }
}
sub readFileXZ($){
  return `xz --decompress --keep --stdout "$_[0]"`;
}

sub writeFile($$){
  my ($file, $contents) = @_;
  open FH, "> $file" or die "ERROR: could not write $file\n$!\n";
  print FH $contents;
  close FH;
}

sub isExecAvailable($){
  my ($exec) = @_;
  system "type \"$exec\" >/dev/null 2>/dev/null";
  return $? == 0 ? 1 : 0;
}

sub nowMillis(){
  return int(time * 1000.0 + 0.5);
}

sub getUUID(){
  return Data::UUID->new->create_str();
}

sub run(@){
  print "@_\n";
  system @_;
  if($? != 0){
    die "ERROR: command failed\n@_\n";
  }
}

&main(@ARGV);
